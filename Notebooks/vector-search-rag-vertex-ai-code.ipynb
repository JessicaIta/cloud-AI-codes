{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d4b24391-4f13-4d6a-892a-fe5129797dc2",
   "metadata": {},
   "source": [
    "# Criando uma RAG com Vector Search e Langchain\n",
    "\n",
    "Notebook com demonstração de como  trabalhar com o Vector na VertexAI e criar uma RAG com Langchain, Gemini e Vector Search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c108ad54-5ea0-4c4a-8f88-7acf86e62021",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependências\n",
    "\n",
    "!pip install langchain-community pypdf langchain-text-splitters langchain-google-vertexai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efe75ccc-d57f-4b49-8d82-320acca1e24f",
   "metadata": {},
   "source": [
    "## Criando o Índice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d77f2d8-4a81-4e94-bcfd-dea801f54405",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Setando o projeto\n",
    "PROJECT_ID = ! gcloud config get project\n",
    "PROJECT_ID = PROJECT_ID[0]\n",
    "LOCATION = \"us-central1\"\n",
    "    \n",
    "BUCKET = \"tutorial-index-rag\"\n",
    "BUCKET_URI = f\"gs://{BUCKET}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de925d10-e7ef-45a2-9024-9cf2835ad524",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Criando o Bucket\n",
    "\n",
    "from google.cloud import storage\n",
    "\n",
    "\n",
    "def create_bucket(bucket_name, LOCATION):\n",
    "    \"\"\"\n",
    "    Create a new bucket \n",
    "    \"\"\"\n",
    "\n",
    "    storage_client = storage.Client()\n",
    "\n",
    "    bucket = storage_client.bucket(bucket_name)\n",
    "    new_bucket = storage_client.create_bucket(bucket, location=LOCATION)\n",
    "\n",
    "    print(f'Bucket {new_bucket.name} criado')\n",
    "\n",
    "create_bucket(BUCKET, LOCATION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e89dc0a-156b-4f25-84a6-72f4606e6f5f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Inicializando a AI Platform\n",
    "\n",
    "from google.cloud import aiplatform\n",
    "\n",
    "aiplatform.init(project=PROJECT_ID, location=LOCATION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61dd6e47-8086-4403-8eb1-4c3daa8d160a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Criando o Índice\n",
    "\n",
    "'''\n",
    "Um índice de lote é para quando você deseja atualizar seu índice em lote, com dados que foram armazenados durante um determinado período de tempo, \n",
    "como sistemas que são processados semanalmente ou mensalmente. Um índice de streaming é quando você deseja que os dados do índice sejam atualizados \n",
    "à medida que novos dados são adicionados ao seu armazenamento de dados. O tipo que você escolhe é importante, pois a configuração e os requisitos são diferentes.\n",
    "'''\n",
    "\n",
    "my_index = aiplatform.MatchingEngineIndex.create_tree_ah_index(\n",
    "    display_name=\"embedvector-tutorial-index\",\n",
    "    dimensions=768,\n",
    "    approximate_neighbors_count=20,\n",
    "    distance_measure_type=\"DOT_PRODUCT_DISTANCE\",\n",
    "    index_update_method=\"STREAM_UPDATE\",  # BATCH_UPDATE , STREAM_UPDATE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd578ff4-1293-47bc-9142-7995952c39ad",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Criando o Endpoint do Índice\n",
    "\n",
    "my_index_endpoint = aiplatform.MatchingEngineIndexEndpoint.create(\n",
    "    display_name=\"embedvector-tutorial-index-endpoint\",\n",
    "    public_endpoint_enabled=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9baa867c-67af-4baa-b50f-efffe82348f4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Realizando o Deploy\n",
    "\n",
    "DEPLOYED_INDEX_ID = \"embedvector_tutorial_deployed\"\n",
    "my_index_endpoint.deploy_index(index=my_index, deployed_index_id=DEPLOYED_INDEX_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "990a0cba-9c26-4419-9946-6218f9982e78",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print (my_index.name)\n",
    "print (my_index_endpoint.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7da4d85-9c9e-464d-8fce-09dfb68bfd2a",
   "metadata": {},
   "source": [
    "## Geração de Embeddings do PDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a11aba8e-9b40-4ea2-8d7c-c421e8807f8c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Índice\n",
    "my_index = aiplatform.MatchingEngineIndex(index_name=my_index.name)\n",
    "\n",
    "# Endpoint do Índice\n",
    "my_index_endpoint = aiplatform.MatchingEngineIndexEndpoint(my_index_endpoint.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eddf06d-e742-467e-a98d-7517424a405d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain_google_vertexai import (\n",
    "    VectorSearchVectorStore,\n",
    "    VectorSearchVectorStoreDatastore,\n",
    ")\n",
    "\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import CharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e68706aa-2b17-41f3-9d73-4e1af65a22f1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def prepare_document_texts(file):\n",
    "\n",
    "    loader = PyPDFLoader(file)\n",
    "    \n",
    "    documents = loader.load()\n",
    "    \n",
    "    text_splitter = CharacterTextSplitter(\n",
    "            separator=\"\\n\", chunk_size=1000, chunk_overlap=20\n",
    "    )\n",
    "\n",
    "    docs = text_splitter.split_documents(documents)\n",
    "    \n",
    "    texts = []\n",
    "\n",
    "    texts.extend(doc.page_content for doc in docs)\n",
    "    \n",
    "    return texts\n",
    "\n",
    "texts = prepare_document_texts(\"vacinas.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef9f231a-9e82-414b-92c2-dd366807405e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Embedding documentos\n",
    "\n",
    "from langchain_google_vertexai import VertexAIEmbeddings\n",
    "\n",
    "\n",
    "embedding_model = VertexAIEmbeddings(model=\"text-multilingual-embedding-002\")\n",
    "\n",
    "vector_store = VectorSearchVectorStore.from_components(\n",
    "    project_id=PROJECT_ID,\n",
    "    region=LOCATION,\n",
    "    gcs_bucket_name=BUCKET,\n",
    "    index_id=my_index.name,\n",
    "    endpoint_id=my_index_endpoint.name,\n",
    "    embedding=embedding_model,\n",
    ")\n",
    "\n",
    "vector_store.add_texts(texts=texts, is_complete_overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f00751b-a431-45ec-958d-a6c0f1fda3e0",
   "metadata": {},
   "source": [
    "## Busca por Similaridade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "069ff72b-4d03-4fe2-9629-389eaca6278a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Busca por Similaridade\n",
    "\n",
    "vector_store.similarity_search(\"vacina\", k=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c14fed3a-b374-4f3d-bcb5-365b11b7ad60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# VectorStore como Retriever\n",
    "\n",
    "retriever = vector_store.as_retriever()\n",
    "\n",
    "# Pergunta\n",
    "retriever.invoke(\"Quais são as vacinas recomendadas para idosos?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83e52600-1ccb-4509-942f-41aedba1ae00",
   "metadata": {},
   "source": [
    "## RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d4c7ffb-6374-4f64-b0a5-165ec21497e6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain_core.messages import SystemMessage, HumanMessage\n",
    "from langchain_google_vertexai import VertexAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e89a59c-e182-4cee-a126-54c90b17a91f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a system prompt that tells the model how to use the retrieved context\n",
    "system_prompt = \"\"\"Você é um assistente para tarefas de resposta a perguntas. \n",
    "Use as seguintes partes do contexto recuperado para responder à pergunta. \n",
    "Se você não sabe a resposta, basta dizer que não sabe. \n",
    "Use no máximo três frases e mantenha a resposta concisa.\n",
    "Contexto: {context}:\"\"\"\n",
    "\n",
    "    \n",
    "\n",
    "def retrieve_contexts(question:str)-> str: \n",
    "    # Recuperando contextos \n",
    "    docs = retriever.invoke(question)\n",
    "\n",
    "    # Combinando os contextos \n",
    "    docs_text = \"\".join(d.page_content for d in docs)\n",
    "    \n",
    "    return docs_text\n",
    "\n",
    "\n",
    "def generate_answer(question: str)-> str:\n",
    "     \n",
    "    # Update the model as needed\n",
    "    llm = VertexAI(model_name=\"gemini-2.0-flash-001\")\n",
    "    \n",
    "    contexto = retrieve_contexts(question)\n",
    "    \n",
    "    system_prompt_fmt = system_prompt.format(context=contexto)\n",
    "\n",
    "    response = llm.invoke([SystemMessage(content=system_prompt_fmt),\n",
    "                          HumanMessage(content=question)])\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d71cba6-b585-4c1b-ab51-e640ee8097f0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "### Perguntas\n",
    "question = \"\"\"Quais vacinas um adulto deve tomar?\"\"\"\n",
    "\n",
    "resposta = generate_answer(question)\n",
    "\n",
    "print(resposta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6849d29-2da8-4324-b54d-38e5f6377c0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Perguntas\n",
    "question = \"\"\"Quais vacinas uma criança deve tomar durante o primeiro ano de vida?\"\"\"\n",
    "\n",
    "resposta = generate_answer(question)\n",
    "\n",
    "print(resposta)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c87a1cd-e898-45e8-aa1c-45c9ab2ebd54",
   "metadata": {},
   "source": [
    "## Listando os Índices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf64e1c0-0df2-4b92-b81a-c520fe12289b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Initialize the Vertex AI client\n",
    "aiplatform.init(project=PROJECT_ID, location=LOCATION)\n",
    "\n",
    "# List Indexes\n",
    "aiplatform.MatchingEngineIndex.list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbc74d5d-0c5b-409a-b89f-a5e357dbfbea",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# List Indexes\n",
    "aiplatform.MatchingEngineIndexEndpoint.list()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5fb633f-6d33-4b02-9752-067688cec2d8",
   "metadata": {},
   "source": [
    "### Limpando o Índice e Bucket na Google Cloud (Opcional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4041838b-31cc-4d38-a1c0-53e5012ad4af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Desfazer Deploy do Índice\n",
    "my_index_endpoint.undeploy_index(deployed_index_id=DEPLOYED_INDEX_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4596c445-1a0a-4bc3-a1cc-e9825ffe4f43",
   "metadata": {},
   "outputs": [],
   "source": [
    "input(\"Pressione Enter para deletar o Endpoint do Índice e o Índice:\")\n",
    "\n",
    "# deletar Index Endpoint\n",
    "my_index_endpoint.undeploy_all()\n",
    "my_index_endpoint.delete(force=True)\n",
    "\n",
    "# deletar Index\n",
    "my_index.delete()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcae1163-4891-4dd7-beb5-681a7493f8de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apagar Cloud Storage bucket\n",
    "! gcloud storage rm {BUCKET_URI} --recursive"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a8b6a96-7493-45cd-ae47-ee3bd570c6cd",
   "metadata": {},
   "source": [
    "Referências\n",
    "\n",
    "https://cloud.google.com/vertex-ai/docs/vector-search/create-manage-index?hl=pt-br#create-index-batch\n",
    "\n",
    "https://python.langchain.com/v0.1/docs/integrations/vectorstores/google_vertex_ai_vector_search/\n",
    "\n",
    "https://medium.com/google-cloud-brasil/rag-super-customizado-com-vertex-ai-vector-search-e-langchain-53f2d7a8d4b8\n",
    "\n",
    "https://github.com/GoogleCloudPlatform/generative-ai/blob/main/embeddings/intro-textemb-vectorsearch.ipynb\n",
    "\n",
    "#VertexAISprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ba55a3e-6f73-4251-be2f-f2014a726658",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-base-py",
   "name": "workbench-notebooks.m127",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m127"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel) (Local)",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
